{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JyDKqQNYn2",
        "outputId": "327f2218-a1d7-4700-bf65-001c7685b701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzLyZdNwNlrn",
        "outputId": "54442c30-325e-41a8-ae97-36f2d6187b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/unsplash-dataset/curated-data\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/unsplash-dataset/curated-data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlpVL2lbNz6z",
        "outputId": "904536d0-85a5-43c7-f186-9a9ac8d654d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/unsplash-dataset/curated-data\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkkF9ccPN1mS",
        "outputId": "de79d05a-6102-48df-e273-96df04511c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 251, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 251 (delta 3), reused 2 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (251/251), 8.93 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the CLIP repository\n",
        "!git clone https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtTesB5OWZU"
      },
      "source": [
        "**List the Photos folder images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPfhK26TPz_k"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_xvmUjLOAaw",
        "outputId": "d7007145-f7dc-4a77-c076-8982f82ed509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Photos found: 1000\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "photos_path = Path(\"/content/drive/My Drive/unsplash-dataset/curated-data/photos\")\n",
        "\n",
        "photos_files = list(photos_path.glob(\"*.jpg\"))\n",
        "# photos_files[:20]\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Photos found: {len(photos_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dDYakE_Odjt"
      },
      "source": [
        "**Load the CLIP API from OpenAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHOgEyX6OsGs",
        "outputId": "d0e6d73a-f3db-4f78-b34c-a1cff434830d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/unsplash-dataset/curated-data\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldy4snq5OU-f",
        "outputId": "ae0f2840-190d-43ff-9267-c111117a07a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 86.8MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import clip\n",
        "import torch\n",
        "from PIL import Image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "#COMPUTE FEATURE VECTOR FOR THE IMAGES\n",
        "def compute_clip_features(photos_batch):\n",
        "    photos = [Image.open(photo_file) for photo_file in photos_batch]\n",
        "\n",
        "    #batch processing\n",
        "    photos_preprocessed = torch.stack([preprocess(photo) for photo in photos]).to(device)\n",
        "    with torch.no_grad():\n",
        "        #encode photos for feature vectors\n",
        "        photos_features = model.encode_image(photos_preprocessed)\n",
        "        photos_features /= photos_features.norm(dim=-1, keepdim=True)\n",
        "    #feature vectors back to the CPU and convert to numpy\n",
        "    return photos_features.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc0RnqtRPeRv",
        "outputId": "094e73d6-51f1-4a03-f5e6-caf805ebeb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1/20\n",
            "Processing batch 2/20\n",
            "Processing batch 3/20\n",
            "Processing batch 4/20\n",
            "Processing batch 5/20\n",
            "Processing batch 6/20\n",
            "Processing batch 7/20\n",
            "Processing batch 8/20\n",
            "Processing batch 9/20\n",
            "Processing batch 10/20\n",
            "Processing batch 11/20\n",
            "Processing batch 12/20\n",
            "Processing batch 13/20\n",
            "Processing batch 14/20\n",
            "Processing batch 15/20\n",
            "Processing batch 16/20\n",
            "Processing batch 17/20\n",
            "Processing batch 18/20\n",
            "Processing batch 19/20\n",
            "Processing batch 20/20\n"
          ]
        }
      ],
      "source": [
        "#defining preprocssing batch size\n",
        "batch_size = 50\n",
        "\n",
        "#path for output feature vectors\n",
        "features_path = Path(\"/content/drive/My Drive/unsplash-dataset/curated-data/features\")\n",
        "\n",
        "#number of batches\n",
        "batches = math.ceil(len(photos_files) / batch_size)\n",
        "\n",
        "#Process each batch\n",
        "for i in range(batches):\n",
        "    print(f\"Processing batch {i+1}/{batches}\")\n",
        "\n",
        "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
        "    batch_features_path = features_path / f\"{i:010d}.npy\"\n",
        "\n",
        "    #error handling\n",
        "    if not batch_features_path.exists():\n",
        "        try:\n",
        "            batch_files = photos_files[i*batch_size : (i+1)*batch_size]\n",
        "            #compute features\n",
        "            batch_features = compute_clip_features(batch_files)\n",
        "            np.save(batch_features_path, batch_features)\n",
        "\n",
        "            #photos id csv for backup\n",
        "            photo_ids = [photo_file.name.split(\".\")[0] for photo_file in batch_files]\n",
        "            photo_ids_data = pd.DataFrame(photo_ids, columns=['photo_id'])\n",
        "            photo_ids_data.to_csv(batch_ids_path, index=False)\n",
        "        except:\n",
        "            # Catch problems with the processing to make the process more robust\n",
        "            print(f'Problem with batch {i}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ABkEfPl6QCLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3957481-2583-491d-c912-67ec432c17a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/unsplash-dataset/curated-data/features\n"
          ]
        }
      ],
      "source": [
        "#load feature vector files\n",
        "features_list = [np.load(features_file) for features_file in sorted(features_path.glob(\"*.npy\"))]\n",
        "\n",
        "# Concatenate the features and store in a merged file\n",
        "features = np.concatenate(features_list)\n",
        "np.save(features_path / \"features.npy\", features)\n",
        "\n",
        "# Load all the photo IDs\n",
        "photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob(\"*.csv\"))])\n",
        "photo_ids.to_csv(features_path / \"photo_ids.csv\", index=False)\n",
        "print(features_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDBO60ubStAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}